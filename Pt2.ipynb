{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM AI Enterprise Workflow Capstone\n",
    "\n",
    "## Part 2: Model Building & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Feature Engineering](#first-bullet)\n",
    "* [Update Log Files](#second-bullet)\n",
    "* [Model Selection](#third-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take in the time series data from the data ingestion and convert to a dictionary with keys for each country and features that describe revenue from past weeks and the previous year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting feature_engineering.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile feature_engineering.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from data_ingestion import fetch_ts\n",
    "\n",
    "\n",
    "def engineer_features(df, training = True):\n",
    "\n",
    "    '''\n",
    "    convert data into dictionary and adding features for previous days revenue\n",
    "    '''\n",
    "\n",
    "    dates = df['date'].values.copy()\n",
    "    dates = dates.astype('datetime64[D]')\n",
    "\n",
    "    eng_features = defaultdict(list)\n",
    "    previous = [7, 14, 28, 70]\n",
    "    y = np.zeros(dates.size)\n",
    "    \n",
    "    for d, day in enumerate(dates):\n",
    "\n",
    "        for num in previous:\n",
    "            \n",
    "            current = np.datetime64(day, 'D') \n",
    "            prev = current - np.timedelta64(num, 'D')\n",
    "            \n",
    "            mask = np.in1d(dates, np.arange(prev, current, dtype = 'datetime64[D]'))\n",
    "            eng_features['previous_{}'.format(num)].append(df[mask]['revenue'].sum())\n",
    " \n",
    "        plus_30 = current + np.timedelta64(30, 'D')\n",
    "    \n",
    "        mask = np.in1d(dates, np.arange(current, plus_30, dtype = 'datetime64[D]'))\n",
    "        y[d] = df[mask]['revenue'].sum()\n",
    "\n",
    "        start_date = current - np.timedelta64(365, 'D')\n",
    "        stop_date = plus_30 - np.timedelta64(365, 'D')\n",
    "        \n",
    "        mask = np.in1d(dates, np.arange(start_date, stop_date, dtype = 'datetime64[D]'))\n",
    "        eng_features['previous_year'].append(df[mask]['revenue'].sum())\n",
    "\n",
    "        minus_30 = current - np.timedelta64(30, 'D')\n",
    "        \n",
    "        mask = np.in1d(dates, np.arange(minus_30, current,dtype = 'datetime64[D]'))\n",
    "        eng_features['recent_invoices'].append(df[mask]['unique_invoices'].mean())\n",
    "        eng_features['recent_views'].append(df[mask]['total_views'].mean())\n",
    "\n",
    "    X = pd.DataFrame(eng_features)\n",
    "    X.fillna(0, inplace = True)\n",
    "    \n",
    "    mask = X.sum(axis = 1) > 0\n",
    "    \n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    dates = dates[mask]\n",
    "    \n",
    "    X.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    if training == True:\n",
    "        \n",
    "        mask = np.arange(X.shape[0]) < np.arange(X.shape[0])[-30]\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        dates = dates[mask]\n",
    "        X.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return(X, y, dates)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    run_start = time.time()\n",
    "    \n",
    "    data_dir = os.path.join('.', 'data', 'cs-train')\n",
    "    df = fetch_ts(data_dir)\n",
    "    \n",
    "    m, s = divmod(time.time() - run_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    \n",
    "    print('run time:', '%d:%02d:%02d'%(h, m, s))\n",
    "    print('feature engineering complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 0:00:00\n",
      "feature engineering complete\n"
     ]
    }
   ],
   "source": [
    "%run feature_engineering.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Log Files <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update the train log with the timestamp, data shape, evaluation metric, and runtime. \n",
    "- Update the predict log with the timestamp, predicted value, probability value, and runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting logger.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile logger.py\n",
    "\n",
    "import time, os, re, csv, sys, uuid, joblib\n",
    "from datetime import date\n",
    "\n",
    "if not os.path.exists(os.path.join('.', 'logs')):\n",
    "    os.mkdir('logs')\n",
    "    \n",
    "    \n",
    "def update_train_log(data_shape, eval_test, runtime, model_vers, test = False):\n",
    "    \n",
    "    '''\n",
    "    update train log file\n",
    "    '''\n",
    "    \n",
    "    today = date.today()\n",
    "    \n",
    "    if test:\n",
    "        logfile = os.path.join('logs', 'train-test.log')\n",
    "    else:\n",
    "        logfile = os.path.join('logs', 'train-{}-{}.log'.format(today.year, today.month))\n",
    "        \n",
    "    header = ['unique_id', 'timestamp', 'x_shape', 'eval_test', 'model_version', 'runtime']\n",
    "    \n",
    "    write_header = False\n",
    "    \n",
    "    if not os.path.exists(logfile):\n",
    "        write_header = True\n",
    "        \n",
    "    with open(logfile, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter = ',')\n",
    "        \n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "            \n",
    "        to_write = map(str, [uuid.uuid4(), time.time(), data_shape, eval_test, model_vers, runtime])\n",
    "        writer.writerow(to_write)   \n",
    "    \n",
    "    \n",
    "def update_predict_log(y_pred, y_proba, query, runtime, model_vers, test = False):\n",
    "    \n",
    "    '''\n",
    "    update predict log file\n",
    "    '''\n",
    "    \n",
    "    today = date.today()\n",
    "    \n",
    "    if test:\n",
    "        logfile = os.path.join('logs', 'predict-test.log')\n",
    "    else:\n",
    "        logfile = os.path.join('logs', 'predict-{}-{}.log'.format(today.year, today.month))\n",
    "        \n",
    "    header = ['unique_id', 'timestamp', 'y_pred', 'y_proba', 'query', 'model_version', 'runtime']\n",
    "    \n",
    "    write_header = False\n",
    "    \n",
    "    if not os.path.exists(logfile):\n",
    "        write_header = True\n",
    "    \n",
    "    with open(logfile, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter = ',')\n",
    "        \n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "\n",
    "        to_write = map(str, [uuid.uuid4(), time.time(), y_pred, y_proba, query, model_vers, runtime])\n",
    "        writer.writerow(to_write)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from model import model_vers\n",
    "    \n",
    "    update_train_log(str((100,10)), \"{'rmse':0.5}\", \"00:00:01\",\n",
    "                     model_vers, test = True)\n",
    "\n",
    "    update_predict_log('[0]', '[0.6, 0.4]', '[\"united_states\", 24, \"aavail_basic\", 8]', '00:00:01',\n",
    "                       model_vers, test = True)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run logger.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through models and choose the optimal model for each country based off RMSE. Train each country's data with the chosen model, load the model, and then predict the revenue given a country and date.\n",
    "\n",
    "As our business opportunity revolves around predicting a numeric value for future revenue, we will iterate through different regressors and output their RMSE values to determine the best model. \n",
    "\n",
    "Suite of Models:\n",
    "- Random Forest Regressor\n",
    "- Ada Boost Regressor\n",
    "- Gradient Boosting Regressor\n",
    "\n",
    "Adjusted Parameters:\n",
    "- Number of Estimators\n",
    "- Learning Rate\n",
    "- Maximum Number of Features\n",
    "\n",
    "Hyperparameters were tuned for each algorithm with the use of scikit-learn classes such as `Pipeline` and `GridSearchCV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib as joblib\n",
    "\n",
    "from data_ingestion import fetch_ts\n",
    "from feature_engineering import engineer_features\n",
    "from logger import update_predict_log, update_train_log\n",
    "\n",
    "model_dir = os.path.join('models')\n",
    "model_vers = 0.1\n",
    "\n",
    "\n",
    "def _model_train(df, tag, test = False):\n",
    "    \n",
    "    '''\n",
    "    loop through and train different models\n",
    "    '''\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    X, y, dates = engineer_features(df)\n",
    "    \n",
    "    if test:\n",
    "        n_samples = int(np.round(0.3 * X.shape[0]))\n",
    "        subset_indices = np.random.choice(np.arange(X.shape[0]), n_samples,\n",
    "                                          replace = False).astype(int)\n",
    "        mask = np.in1d(np.arange(y.size), subset_indices)\n",
    "        y = y[mask]\n",
    "        X = X[mask]\n",
    "        dates = dates[mask]\n",
    "        \n",
    "    X, y, dates = engineer_features(df)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 100)\n",
    "    \n",
    "    reg_names = ['RF', 'ADA', 'GB']\n",
    "    regressors = (RandomForestRegressor(random_state = 100), AdaBoostRegressor(random_state = 100), \n",
    "                  GradientBoostingRegressor(random_state = 100))\n",
    "\n",
    "    params = [\n",
    "        {'reg__n_estimators': [10, 15, 20, 25],\n",
    "         'reg__max_features': [3, 4, 5]\n",
    "        },\n",
    "        {'reg__n_estimators': [10, 15, 20, 25],\n",
    "         'reg__learning_rate': [1, 0.1, 0.01, 0.001]\n",
    "        },\n",
    "        {'reg__n_estimators': [10, 15, 20, 25],\n",
    "         'reg__max_features': [3, 4, 5]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    models = {}\n",
    "    \n",
    "    for iteration, (name, regressor, param) in enumerate(zip(reg_names, regressors, params)):\n",
    "        \n",
    "        pipeline = Pipeline(steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('reg', regressor)\n",
    "        ])\n",
    "        \n",
    "        grid = GridSearchCV(pipeline, param_grid = param, scoring = 'neg_mean_squared_error', cv = 5, \n",
    "                           n_jobs = -1, return_train_score = True)\n",
    "        \n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        models[name] = grid, grid.best_estimator_.get_params()\n",
    "        \n",
    "    test_scores = []\n",
    "    \n",
    "    for key, model in models.items():\n",
    "        \n",
    "        y_pred = model[0].predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "        test_scores.append(rmse)\n",
    "        \n",
    "    best_model = reg_names[np.argmin(test_scores)]\n",
    "    opt_model, params = models[best_model]\n",
    "    \n",
    "    country_name = tag.replace('_', ' ').title()\n",
    "    \n",
    "    print('Model Results for {}: \\n'.format(country_name))\n",
    "    \n",
    "    print('RMSE Values:')\n",
    "    \n",
    "    for i in range(len(reg_names)):\n",
    "        print('{}: {} \\n'.format(reg_names[i], test_scores[i]))\n",
    "\n",
    "    print('Best Model: \\n {}'.format(next(iter(models.items()))[1][1]['reg']))\n",
    "    \n",
    "    print('============================================================')\n",
    "    \n",
    "    if test:\n",
    "        saved_model = os.path.join(model_dir, 'test-{}-model-{}.joblib'.format(tag, re.sub('\\.', '_', str(model_vers))))\n",
    "    else:\n",
    "        saved_model = os.path.join(model_dir, 'prod-{}-model-{}.joblib'.format(tag, re.sub('\\.', '_', str(model_vers))))\n",
    "                                   \n",
    "    joblib.dump(opt_model, saved_model)\n",
    "    \n",
    "    m, s = divmod(time.time() - time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    runtime = '%03d:%02d:%02d'%(h, m, s)\n",
    "\n",
    "    update_train_log((str(dates[0]), str(dates[-1])), {'rmse': max(test_scores)}, runtime, model_vers, test = True)\n",
    "    \n",
    "    \n",
    "def model_train(data_dir, test = False):\n",
    "\n",
    "    '''\n",
    "    train models for each country and select optimal model\n",
    "    '''\n",
    "    \n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    ts_data = fetch_ts(data_dir)\n",
    "\n",
    "    for country, df in ts_data.items():\n",
    "        _model_train(df, country, test = test) \n",
    "        \n",
    "        \n",
    "def model_load(data_dir = None, training = True):\n",
    "\n",
    "    '''\n",
    "    load trained model\n",
    "    '''\n",
    "\n",
    "    if not data_dir:\n",
    "        data_dir = os.path.join('.', 'data', 'cs-train')\n",
    "    \n",
    "    models = [f for f in os.listdir(os.path.join('.', 'models')) if f.endswith('.joblib')]\n",
    "\n",
    "    if len(models) == 0:\n",
    "        raise Exception('model cannot be found')\n",
    "\n",
    "    all_models = {}\n",
    "    \n",
    "    for model in models:\n",
    "        all_models[re.split('-', model)[1]] = joblib.load(os.path.join('.', 'models', model))\n",
    "\n",
    "    ts_data = fetch_ts(data_dir)\n",
    "    \n",
    "    all_data = {}\n",
    "    \n",
    "    for country, df in ts_data.items():\n",
    "        X, y, dates = engineer_features(df, training = training)\n",
    "        dates = np.array([str(d) for d in dates])\n",
    "        all_data[country] = {'X':X, 'y':y, 'dates': dates}\n",
    "        \n",
    "    return(all_data, all_models)\n",
    "\n",
    "\n",
    "def model_predict(country, year, month, day, all_models = None, test = False):\n",
    "    \n",
    "    '''\n",
    "    predict from model given country and date\n",
    "    '''\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    if not all_models:\n",
    "        all_data, all_models = model_load(training = False)\n",
    "        \n",
    "    if country not in all_models.keys():\n",
    "        raise Exception('model for country {} could not be found'.format(country))\n",
    "\n",
    "    for d in [year, month, day]:\n",
    "        if re.search('\\D', d):\n",
    "            raise Exception('invalid year, month, or day')\n",
    "\n",
    "    model = all_models[country]\n",
    "    data = all_data[country]\n",
    "    \n",
    "    target_date = '{}-{}-{}'.format(year, str(month).zfill(2), str(day).zfill(2))\n",
    "    print(target_date)\n",
    "    \n",
    "    if target_date not in data['dates']:\n",
    "        raise Exception('date {} not in range {}-{}'.format(target_date, data['dates'][0], data['dates'][-1]))\n",
    "        \n",
    "    date_indx = np.where(data['dates'] == target_date)[0][0]\n",
    "    \n",
    "    query = data['X'].iloc[[date_indx]]\n",
    "    \n",
    "    if data['dates'].shape[0] != data['X'].shape[0]:\n",
    "        raise Exception('dimensions mismatch')\n",
    "        \n",
    "    y_pred = model.predict(query)\n",
    "    y_proba = None\n",
    "    \n",
    "    if 'predict_proba' in dir(model) and 'probability' in dir(model):\n",
    "        if model.probability == True:\n",
    "            y_proba = model.predict_proba(query)\n",
    "            \n",
    "    print('y_pred: {}, y_proba: {}'.format(y_pred, y_proba))\n",
    "     \n",
    "    m, s = divmod(time.time() - time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    runtime = '%03d:%02d:%02d'%(h, m, s)\n",
    "\n",
    "    update_predict_log(y_pred, y_proba, target_date, runtime, model_vers, test = test)\n",
    "    \n",
    "    return({'y_pred': y_pred, 'y_proba': y_proba})\n",
    "        \n",
    "      \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    data_dir = os.path.join('.', 'data', 'cs-train')\n",
    "    model_train(data_dir, test = True)\n",
    "\n",
    "    all_data, all_models = model_load()\n",
    "    print('Models Loaded: ',', '.join(all_models.keys()))\n",
    "\n",
    "    country = 'all'\n",
    "    year = '2018'\n",
    "    month = '01'\n",
    "    day = '05'\n",
    "    \n",
    "    result = model_predict(country, year, month, day)\n",
    "    print(result)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results for Portugal: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 481.4510586410663 \n",
      "\n",
      "ADA: 633.5492860870743 \n",
      "\n",
      "GB: 680.0064118013312 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=5, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Belgium: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 98.22937829428255 \n",
      "\n",
      "ADA: 288.44677520183154 \n",
      "\n",
      "GB: 296.7943232262412 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for United Kingdom: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 17626.22868371201 \n",
      "\n",
      "ADA: 39783.33337110975 \n",
      "\n",
      "GB: 32998.49725490522 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Hong Kong: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 1051.5032905496703 \n",
      "\n",
      "ADA: 1106.0305430596782 \n",
      "\n",
      "GB: 1102.4942628993306 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=3, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Eire: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 2200.4029809021904 \n",
      "\n",
      "ADA: 2836.3564780604415 \n",
      "\n",
      "GB: 2424.1056220737473 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for France: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 516.0094058676112 \n",
      "\n",
      "ADA: 875.5355591937176 \n",
      "\n",
      "GB: 796.0253136653572 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Singapore: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 115.00036075530598 \n",
      "\n",
      "ADA: 0.0 \n",
      "\n",
      "GB: 202.41801154816062 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for All: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 26533.121029810914 \n",
      "\n",
      "ADA: 47340.7756528652 \n",
      "\n",
      "GB: 38315.531952386955 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=5, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Norway: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 233.74906763427617 \n",
      "\n",
      "ADA: 298.0831584403795 \n",
      "\n",
      "GB: 249.0391502634099 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=3, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Germany: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 376.3838469259516 \n",
      "\n",
      "ADA: 640.1365872912793 \n",
      "\n",
      "GB: 626.2848097710555 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Netherlands: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 95.07514119966471 \n",
      "\n",
      "ADA: 204.54647830609318 \n",
      "\n",
      "GB: 167.70392361935362 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=5, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Models Loaded:  france, hong_kong, eire, netherlands, singapore, portugal, united_kingdom, norway, germany, belgium, all\n",
      "2018-01-05\n",
      "y_pred: [ 16504.73026667], y_proba: None\n",
      "{'y_pred': array([ 16504.73026667]), 'y_proba': None}\n"
     ]
    }
   ],
   "source": [
    "%run model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
