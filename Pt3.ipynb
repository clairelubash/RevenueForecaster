{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM AI Enterprise Workflow Capstone\n",
    "\n",
    "## Part 3: Model Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Flask API](#first-bullet)\n",
    "* [Unit Tests](#second-bullet)\n",
    "* [Docker Container](#third-bullet)\n",
    "* [Post-Production Analysis](#fourth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask API<a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a Flask API with endpoints for train, predict, and logfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "from flask import Flask, jsonify, request, send_from_directory\n",
    "import os\n",
    "import argparse\n",
    "import joblib\n",
    "import socket\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from model import *\n",
    "from logger import *\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return 'Home Page'\n",
    "    \n",
    "    \n",
    "@app.route('/train', methods = ['GET', 'POST'])\n",
    "def train():\n",
    "    \n",
    "    if not request.json:\n",
    "        return jsonify(False)\n",
    "    \n",
    "    data_dir = os.path.join('.', 'data', 'cs-train')\n",
    "    \n",
    "    model = model_train(data_dir)\n",
    "    \n",
    "    return jsonify(True)\n",
    "\n",
    "    \n",
    "@app.route('/predict', methods = ['GET','POST'])\n",
    "def predict():\n",
    "    \n",
    "    if not request.json:\n",
    "        return jsonify(False)\n",
    "    \n",
    "    _result = model_predict(country = request.json['country'], year = request.json['year'], \n",
    "                            month = request.json['month'], day = request.json['day'])\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for key, item in _result.items():\n",
    "        \n",
    "        if isinstance(item, np.ndarray):\n",
    "            result[key] = item.tolist()\n",
    "        else:\n",
    "            result[key] = item\n",
    "        \n",
    "    return(jsonify(result))\n",
    "    \n",
    "\n",
    "@app.route('/logs/<filename>', methods = ['GET'])\n",
    "def logs(filename):\n",
    "\n",
    "    if not re.search('.log', filename):\n",
    "        return jsonify(False)\n",
    "\n",
    "    log_dir = os.path.join('.', 'logs')\n",
    "    \n",
    "    if not os.path.isdir(log_dir):\n",
    "        return jsonify(False)\n",
    "\n",
    "    file_path = os.path.join(log_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return jsonify(False)\n",
    "    \n",
    "    return send_from_directory(log_dir, filename, as_attachment = True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('-d', '--debug', action = 'store_true', help = 'debug flask')\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    if args['debug']:\n",
    "        app.run(debug = True, port = 8080)\n",
    "    else:\n",
    "        app.run(host = '0.0.0.0', threaded = True , port = 8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"y_pred\": [\n",
      "    16504.730266666662\n",
      "  ], \n",
      "  \"y_proba\": null\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# testing predict endpoint\n",
    "\n",
    "query = {'country': 'all', 'year': '2018', 'month': '1', 'day': '5'}\n",
    "port = 8080\n",
    "r = requests.post('http://localhost:{}/predict'.format(port), json = query)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing train endpoint\n",
    "\n",
    "query = {'data_dir': './data/cs-train'}\n",
    "port = 8080\n",
    "r = requests.post('http://localhost:{}/train'.format(port), json = query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests<a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit tests are organized in a suite for enabling automation. The tests were created for the following functionalities:\n",
    "\n",
    "- Model tests: train, load, predict\n",
    "- API tests: train, predict, logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./unit_tests/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./unit_tests/__init__.py\n",
    "\n",
    "import unittest\n",
    "import getopt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "try:\n",
    "    optlist, args = getopt.getopt(sys.argv[1:], 'v')\n",
    "except getopt.GetoptError:\n",
    "    print(getopt.GetoptError)\n",
    "    print(sys.argv[0] + '-v')\n",
    "    print('... the verbose flag (-v) may be used')\n",
    "    sys.exit()\n",
    "\n",
    "VERBOSE = False\n",
    "RUNALL = False\n",
    "\n",
    "sys.path.append(os.path.realpath(os.path.dirname(__file__)))\n",
    "\n",
    "for o, a in optlist:\n",
    "    if o == '-v':\n",
    "        VERBOSE = True\n",
    "        \n",
    "        \n",
    "from model_tests import *\n",
    "ModelTestSuite = unittest.TestLoader().loadTestsFromTestCase(ModelTest)\n",
    "\n",
    "from api_tests import *\n",
    "ApiTestSuite = unittest.TestLoader().loadTestsFromTestCase(ApiTest)\n",
    "\n",
    "\n",
    "MainSuite = unittest.TestSuite([ModelTestSuite, ApiTestSuite])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./unit_tests/model_tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./unit_tests/model_tests.py\n",
    "\n",
    "import unittest, random\n",
    "\n",
    "from model import *\n",
    "\n",
    "\n",
    "class ModelTest(unittest.TestCase):\n",
    "    \n",
    "    def test_01_train(self):\n",
    "        \n",
    "        data_dir = './data/cs-train'\n",
    "        model_dir = './models'\n",
    "        \n",
    "        model_train(data_dir)\n",
    "        models = [f for f in os.listdir(model_dir) if re.search('test', f)]\n",
    "        \n",
    "        self.assertEqual(len(models), 11)\n",
    "        \n",
    "    def test_02_load(self):    \n",
    "        \n",
    "        all_data, all_models = model_load()\n",
    "        models_loaded = list(all_models.keys())\n",
    "        \n",
    "        model = all_models[random.choice(models_loaded)]\n",
    "        \n",
    "        self.assertTrue('predict' in dir(model))\n",
    "        self.assertTrue('fit' in dir(model))\n",
    "        \n",
    "    def test_03_predict(self):  \n",
    "        \n",
    "        country = 'all'\n",
    "        year = '2018'\n",
    "        month = '01'\n",
    "        day = '05'\n",
    "        \n",
    "        result = model_predict(country, year, month, day)\n",
    "        y_pred = result['y_pred']\n",
    "        \n",
    "        self.assertTrue(y_pred.dtype == np.float64)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results for Portugal: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 481.4510586410663 \n",
      "\n",
      "ADA: 633.5492860870743 \n",
      "\n",
      "GB: 680.0064118013312 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=5, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Belgium: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 98.22937829428255 \n",
      "\n",
      "ADA: 288.44677520183154 \n",
      "\n",
      "GB: 296.7943232262412 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for United Kingdom: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 17626.22868371201 \n",
      "\n",
      "ADA: 39783.33337110975 \n",
      "\n",
      "GB: 32998.49725490522 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Hong Kong: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 1051.5032905496703 \n",
      "\n",
      "ADA: 1106.0305430596782 \n",
      "\n",
      "GB: 1102.4942628993306 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=3, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Eire: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 2200.4029809021904 \n",
      "\n",
      "ADA: 2836.3564780604415 \n",
      "\n",
      "GB: 2424.1056220737473 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for France: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 516.0094058676112 \n",
      "\n",
      "ADA: 875.5355591937176 \n",
      "\n",
      "GB: 796.0253136653572 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Singapore: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 115.00036075530598 \n",
      "\n",
      "ADA: 0.0 \n",
      "\n",
      "GB: 202.41801154816062 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for All: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 26533.121029810914 \n",
      "\n",
      "ADA: 47340.7756528652 \n",
      "\n",
      "GB: 38315.531952386955 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=5, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Norway: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 233.74906763427617 \n",
      "\n",
      "ADA: 298.0831584403795 \n",
      "\n",
      "GB: 249.0391502634099 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=3, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n",
      "Model Results for Germany: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 376.3838469259516 \n",
      "\n",
      "ADA: 640.1365872912793 \n",
      "\n",
      "GB: 626.2848097710555 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results for Netherlands: \n",
      "\n",
      "RMSE Values:\n",
      "RF: 95.07514119966471 \n",
      "\n",
      "ADA: 204.54647830609318 \n",
      "\n",
      "GB: 167.70392361935362 \n",
      "\n",
      "Best Model: \n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=5, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "           oob_score=False, random_state=100, verbose=0, warm_start=False)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-05\n",
      "y_pred: [ 16504.73026667], y_proba: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 140.056s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run unit_tests/model_tests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./unit_tests/api_tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./unit_tests/api_tests.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import unittest\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "port = 8080\n",
    "\n",
    "try:\n",
    "    requests.post('http://localhost:{}/predict'.format(port))\n",
    "    server_available = True\n",
    "except:\n",
    "    server_available = False\n",
    "    \n",
    "\n",
    "class ApiTest(unittest.TestCase):\n",
    "    \n",
    "    @unittest.skipUnless(server_available, 'local server is not running')\n",
    "    def test_01_train(self):\n",
    "        \n",
    "        query = {'data_dir': './data/cs-train'}\n",
    "        r = requests.post('http://localhost:{}/train'.format(port), json = query)\n",
    "        \n",
    "        train_complete = re.sub('\\W+', '', r.text)\n",
    "        self.assertEqual(train_complete, 'true')\n",
    "    \n",
    "    @unittest.skipUnless(server_available, 'local server is not running')\n",
    "    def test_02_predict(self):\n",
    "    \n",
    "        query = {'country': 'all', 'year': '2018', 'month': '1', 'day': '5'}\n",
    "        r = requests.post('http://localhost:{}/predict'.format(port), json = query)\n",
    "        response = json.loads(r.text)\n",
    "\n",
    "        self.assertTrue(isinstance(response['y_pred'][0], float))\n",
    "    \n",
    "    @unittest.skipUnless(server_available, 'local server is not running')\n",
    "    def test_03_logs(self):\n",
    "    \n",
    "        file_name = 'train-test.log'\n",
    "        request_json = {'file': 'train-test.log'}\n",
    "        \n",
    "        r = requests.get('http://localhost:{}/logs/{}'.format(port, file_name))\n",
    "        \n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        \n",
    "        self.assertTrue(os.path.exists(file_name))\n",
    "\n",
    "        if os.path.exists(file_name):\n",
    "            os.remove(file_name)\n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 144.129s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run unit_tests/api_tests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_tests.py\n",
    "\n",
    "import sys\n",
    "import unittest\n",
    "\n",
    "from unit_tests import *\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Container<a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A text file is created containing the dependencies needed for this project. Then the Dockerfile is built to bundle the API, model, and tests. The Docker image ```capstone-ai-app``` is built, and then the container is run through the terminal:\n",
    "\n",
    "```\n",
    "~$ docker build capstone-ai-app .\n",
    "~$ docker run -p 4000:8080 capstone-ai-app\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "cython\n",
    "numpy\n",
    "flask\n",
    "pandas\n",
    "scikit-learn\n",
    "matplotlib\n",
    "seaborn\n",
    "requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.7.5-stretch\n",
    "\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "python3-dev \\\n",
    "build-essential    \n",
    "        \n",
    "WORKDIR /app\n",
    "\n",
    "ADD . /app\n",
    "\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "EXPOSE 80\n",
    "\n",
    "ENV NAME World\n",
    "\n",
    "CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Production Analysis<a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
